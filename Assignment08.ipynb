{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283c69a1-7f39-4052-a482-591cfcde76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4eb959-3db3-4143-b19a-2e42ae50b569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('https://www.gutenberg.org/files/1514/1514-0.txt')\n",
    "play = response.text\n",
    "play = play.split(\"***\")[2]\n",
    "play = play.replace(\"\\n\", \" \")\n",
    "play = play.replace(\"\\r\", \" \")\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25728571-a008-4f5e-91c1-521e6e1be28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent_tokenize(play)\n",
    "words = []\n",
    "for s in sent:\n",
    "    for w in word_tokenize(s):\n",
    "        words.append(w.lower())\n",
    "myStopWords = list(punctuation) + stopwords.words('english')\n",
    "\n",
    "wordsNoStop = []\n",
    "for i in words:\n",
    "    if i.lower() not in myStopWords:\n",
    "        wordsNoStop.append(i.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9aed7e-b41c-4996-84e9-030dfded82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_cytoscape as cyto\n",
    "from dash import html, dcc\n",
    "from dash.dependencies import Input, Output\n",
    "from jupyter_dash import JupyterDash\n",
    "from jupyter_dash.comms import _send_jupyter_config_comm_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ddfda7-b5ef-4bc0-b202-f81d870e8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = play.split('ACT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef62881-aea4-49df-81fe-e8b4728f7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = []\n",
    "for act in acts:\n",
    "    scenes.append(act.split('SCENE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5af3c63-9a1d-49e5-be38-43dd2af388e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = [\n",
    "    'PUCK',\n",
    "    'OBERON',\n",
    "    'TITANIA',\n",
    "    'LYSANDER',\n",
    "    'DEMETRIUS',\n",
    "    'HERMIA',\n",
    "    'HELENA',\n",
    "    'EGEUS',\n",
    "    'THESEUS',\n",
    "    'HIPPOLYTA',\n",
    "    'NICK',\n",
    "    'PETER QUINCE',\n",
    "    'FRANCIS FLUTE',\n",
    "    'ROBIN STARVELING',\n",
    "    'TOM SNOUT',\n",
    "    'SNUG',\n",
    "    'PHILOSTRATE',\n",
    "    'PEASEBLOSSOM',\n",
    "    'COBWEB',\n",
    "    'MOTE',\n",
    "    'MUSTARDSEED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc2e9ff-7e0a-4583-849a-c3c5054b513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "charnum = {}\n",
    "\n",
    "connections = {}\n",
    "for i in range(len(characters)-1):\n",
    "    for j in range(i+1,len(characters)):\n",
    "        connections[(characters[i],characters[j])] = 0\n",
    "\n",
    "for k in characters:\n",
    "    charnum[k] = 0\n",
    "\n",
    "for i in acts:\n",
    "    for j in i.split('SCENE')[1:]:\n",
    "        scenechars = []\n",
    "        for k in characters:\n",
    "            if j.find(k) != -1:\n",
    "                scenechars.append(k)\n",
    "                charnum[k] += 1\n",
    "        for a in range(len(scenechars)-1):\n",
    "            for b in range(a+1,len(scenechars)):\n",
    "                connections[(scenechars[a],scenechars[b])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30cb784f-c17b-4d64-8f73-ffcf3fa7e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphitems = []\n",
    "\n",
    "for k,v in charnum.items():\n",
    "    dashnode = {'data': {'id': k,\n",
    "                         'label': k.title(),\n",
    "                         'size': str(v)}}\n",
    "    graphitems.append(dashnode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c0b011-6f00-47db-9804-c7490409cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in charnum.items():\n",
    "    dashnode = {'data': {'id': k,\n",
    "                         'label': k.title(),\n",
    "                         'size': str(v)}}\n",
    "    graphitems.append(dashnode)\n",
    "\n",
    "for k,v in connections.items():\n",
    "    if v != 0:\n",
    "        dashedge = {'data': {'source': k[0],\n",
    "                             'target': k[1],\n",
    "                             'weight': v}}\n",
    "        graphitems.append(dashedge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "799ccaf8-229c-49e3-b721-19837b149afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_send_jupyter_config_comm_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d194a529-beb9-40df-91bb-9b3cb6c5a3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/jupyter_dash/comms.py:69: RuntimeWarning: coroutine 'Kernel.do_one_iteration' was never awaited\n",
      "  kernel.do_one_iteration()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to communicate with the jupyter_dash notebook or JupyterLab \nextension required to infer Jupyter configuration.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1325/326626489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mJupyterDash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_jupyter_proxy_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/jupyter_dash/jupyter_app.py\u001b[0m in \u001b[0;36minfer_jupyter_proxy_config\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# Assume classic notebook or JupyterLab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0m_request_jupyter_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/jupyter_dash/comms.py\u001b[0m in \u001b[0;36m_request_jupyter_config\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# give up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0;34m\"Unable to communicate with the jupyter_dash notebook or JupyterLab \\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;34m\"extension required to infer Jupyter configuration.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to communicate with the jupyter_dash notebook or JupyterLab \nextension required to infer Jupyter configuration."
     ]
    }
   ],
   "source": [
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd47cdf-e866-4012-ae61-abe254d74d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    cyto.Cytoscape(\n",
    "        layout={'name': 'cose'},\n",
    "        elements=graphitems,\n",
    "        style={'width': '100%', 'height': '1750px'},\n",
    "        stylesheet=[\n",
    "            {\n",
    "                'selector': 'node',\n",
    "                'style': {\n",
    "                    'content':'data(label)',\n",
    "                    'text-halign':'center',\n",
    "                    'text-valign':'center',\n",
    "                    'width': 'data(size)',\n",
    "                    'height': 'data(size)',\n",
    "                    'font-size':4,\n",
    "                    'color': 'blue',\n",
    "                    'text-outline-color': 'white',\n",
    "                    'text-outline-width': 0.2,\n",
    "                    'shape':'circle'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'selector':'edge',\n",
    "                'style': {\n",
    "                    'width':'data(str(int(weight)/100))',\n",
    "                    'line-color': 'blue',\n",
    "                  }\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "])\n",
    "\n",
    "app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a0e20-a2fd-44ca-b6e2-cfe6128bb84e",
   "metadata": {},
   "source": [
    "You can see in the graph that the one character, Snug is all out it's own, and as Snug is a minor character who doesn't even have a first name, it makes sense that Snug is not as interconnected in this graph. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b680f1-3174-4a41-bc0f-09e6a3beb6d4",
   "metadata": {},
   "source": [
    "But one other thing in the main component that is clear is that the graph is an extremely connected graph, meaning that the character all interact with each other. since the whole play is analyzed, although there are 2 parallel storylines, the character all come together in Act 5, so that leads to the interconnectedness of all characters.\n",
    "\n",
    "But still there are some characters who never end up meeting, most mainly the minor characters such as Snug and also to a lesser extent Philostarate as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f8a3f-1b20-4ac8-8ab5-60cd22a82638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca365020-9f8d-42f7-ac5a-9175eb5c42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nxgraphitems = []\n",
    "\n",
    "# for k,v in charnum.items():\n",
    "#     dashnode = k\n",
    "#     graphitems.append(dashnode)\n",
    "\n",
    "for k,v in connections.items():\n",
    "    if v != 0:\n",
    "        dashedge = (k[0],k[1])\n",
    "        nxgraphitems.append(dashedge)\n",
    "    \n",
    "nxgraphitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b807b25-1ad8-4827-97a2-0bb93f61a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from(nxgraphitems)\n",
    "dc = nx.degree_centrality(G)\n",
    "for i in sorted(dc, key=dc.get, reverse=True):\n",
    "    print('{:15s}: {:.3f}'.format(i.title(), dc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc76698-84c5-4c98-9caf-06b2d7f5a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = nx.edge_betweenness_centrality(G)\n",
    "for i in sorted(dc, key=dc.get, reverse=True):\n",
    "    print('{:15s}: {:.3f}'.format(i.title(), dc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c7150-2b80-4360-ac3a-778cd026215e",
   "metadata": {},
   "source": [
    "## Most Important Nodes and Network Density\n",
    "The degree centrality is quite large. This means that the graph must be very dense, which we can already see in the Dash graph above. \n",
    "\n",
    "We also know that the most important nodes are the ones with 1.000 degree centrality, meaning that they're essentially connected to every other character. I'd say \n",
    "that makes them the most important nodes since plays are built on character interactions, so the ones that interact with each other the most must be the most important. \n",
    "\n",
    "I can see that this network analysis is pretty accurate as the main characters, Puck Oberon and Titania are listed among the most important nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711d58e-ab69-4ed8-bd7d-d4b732970a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f621fe-7472-4471-99a4-ec6cd670d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community.centrality import girvan_newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab8cb1-57eb-404d-9cf2-ea000fa7901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = girvan_newman(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc965a41-ed09-4173-b076-eb26b960745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_groups = []\n",
    "for com in next(communities):\n",
    "    node_groups.append(list(com))\n",
    " \n",
    "print(node_groups)\n",
    " \n",
    "color_map = []\n",
    "for node in G:\n",
    "    if node in node_groups[0]:\n",
    "        color_map.append('pink')\n",
    "    else:\n",
    "        color_map.append('yellow')\n",
    "nx.draw(G, node_color=color_map, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542bb14e-644b-4801-8b9d-abcc5972cbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "552a1298-dd3d-4ce2-940a-14e8e564600e",
   "metadata": {},
   "source": [
    "Through determining the communities using the Girvan Newman method we can see that Philostrate is in a community of their own. This is maybe because the Philostrate is more of a behind the scenes of the play we're examining, so it makes sense that they have much less connections, and then in a community of their own. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bdead-5ac6-4e7e-9bb4-c517d3dc0de0",
   "metadata": {},
   "source": [
    "Lets try adding some more communities! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23660a-c3a7-44ac-9bda-e2628b0925a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "com = girvan_newman(G)\n",
    "coms = []\n",
    "for communities in list(com):\n",
    "    coms.append((tuple(sorted(c) for c in communities)))\n",
    "# node_groups = []\n",
    "# for com in next(communities):\n",
    "#     node_groups.append(list(com))\n",
    " \n",
    "\n",
    "node_groups = []\n",
    "for x in coms[2]:\n",
    "    node_groups.append(x)\n",
    " \n",
    "color_map = []\n",
    "for node in G:\n",
    "    if node in node_groups[0]:\n",
    "        color_map.append('pink')\n",
    "    elif node in node_groups[1]:\n",
    "        color_map.append('green')\n",
    "    else:\n",
    "        color_map.append('yellow')\n",
    "nx.draw(G, node_color=color_map, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ba4f7-fbf9-40a5-b1c6-e0fd33910aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "com = girvan_newman(G)\n",
    "coms = []\n",
    "for communities in list(com):\n",
    "    coms.append((tuple(sorted(c) for c in communities)))\n",
    "# node_groups = []\n",
    "# for com in next(communities):\n",
    "#     node_groups.append(list(com))\n",
    " \n",
    "\n",
    "node_groups = []\n",
    "for x in coms[3]:\n",
    "    node_groups.append(x)\n",
    " \n",
    "color_map = []\n",
    "for node in G:\n",
    "    if node in node_groups[0]:\n",
    "        color_map.append('pink')\n",
    "    elif node in node_groups[1]:\n",
    "        color_map.append('green')\n",
    "    elif node in node_groups[2]:\n",
    "        color_map.append('blue')\n",
    "    else:\n",
    "        color_map.append('yellow')\n",
    "nx.draw(G, node_color=color_map, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb88f0-233d-42f9-af78-6c18f6a0b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "com = girvan_newman(G)\n",
    "coms = []\n",
    "for communities in list(com):\n",
    "    coms.append((tuple(sorted(c) for c in communities)))\n",
    "# node_groups = []\n",
    "# for com in next(communities):\n",
    "#     node_groups.append(list(com))\n",
    " \n",
    "\n",
    "node_groups = []\n",
    "for x in coms[4]:\n",
    "    node_groups.append(x)\n",
    " \n",
    "color_map = []\n",
    "for node in G:\n",
    "    if node in node_groups[0]:\n",
    "        color_map.append('pink')\n",
    "    elif node in node_groups[1]:\n",
    "        color_map.append('orange')\n",
    "    elif node in node_groups[2]:\n",
    "        color_map.append('yellow')\n",
    "    elif node in node_groups[3]:\n",
    "        color_map.append('green')\n",
    "    else:\n",
    "        color_map.append('blue')\n",
    "nx.draw(G, node_color=color_map, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fae11aa-0a7c-4ec4-82a9-0716c373fb8d",
   "metadata": {},
   "source": [
    "An interesting thing happens with these communities, as k increases (or the most important node changes), it flips from separating the least connected edges, and then one by one strippng off the most connected communities after. Since it peels off the most central nodes first, I'm guessing that in the later k numbers, the most interconnected (and \"important\" character that interact with most other characters) are peeled off into their own communities first. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9851ead-9fd4-470c-b072-857604fadc41",
   "metadata": {},
   "source": [
    "I've tailored the graph to have different colors and also have more communities that point out the most important characters, in the order of the rainbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b790221-49e1-4bda-b566-68c96ea2862e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
